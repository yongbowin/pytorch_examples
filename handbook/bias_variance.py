# -*- coding:utf-8 -*-
"""
@Time  : 3/14/20 5:24 PM
@Author: Yongbo Wang
@Email : yongbowin@outlook.com
@File  : bias_variance.py
@Desc  : reference from https://github.com/zergtant/pytorch-handbook/blob/master/chapter2/2.2-deep-learning-basic-mathematics.ipynb
        方差和偏差
"""

"""
当我们的模型表现不佳时，通常是出现两种问题，一种是 高偏差 问题，另一种是 高方差 问题。识别它们有助于选择正确的优化方式，所以我们先来看下 偏差 与 方差 的意义。 
- 偏差: 描述模型输出结果的期望与样本真实结果的差距。 即刻画了学习算法本身的拟合能力
- 方差: 描述模型对于给定值的输出稳定性。 即模型的泛化能力

就像打靶一样，偏差描述了我们的射击总体是否偏离了我们的目标，而方差描述了射击准不准。
高方差： （过拟合）
    靶子上的点比较分散，
    即模型对于训练数据拟合度太高了，失去了泛化的能力。
高偏差： （欠拟合）
    靶子上的点离中心比较远， 
    即我们的模型并没有很好的去适配现有的数据，拟合度不够。

如何解决这两种情况呢？
高方差： （过拟合） ：
    1.使用更多的数据；
    2.正则化（ regularization）；增加正则化参数 λ
    3.寻找合适的网络结构；
    4.减少特征数量，去除非主要的特征
高偏差： （欠拟合）：
    1.增加网络结构，如增加隐藏层数目；
    2.训练更长时间；
    3.寻找合适的网络架构，使用更大的NN结构；
    4.引入更多的相关特征
    5.采用多项式特征
    6.减小正则化参数 λ

利用正则化来解决 [高方差（过拟合）] 的问题，正则化是在 损失函数 中加入一项正则化项，[惩罚模型的复杂度]，这里我们简单的介绍一下正则化的概念
    1. L1正则化 ： 损失函数基础上加上权重参数的绝对值
    2. L2正则化 ： 损失函数基础上加上权重参数的平方和
需要说明的是：l1 相比于 l2 会更容易获得稀疏解， reference from https://www.zhihu.com/question/37096933/answer/70507353
"""

